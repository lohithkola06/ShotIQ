{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# ensure project root on path for src imports\n",
        "sys.path.append(os.path.abspath(\"..\"))\n",
        "\n",
        "from src.features import build_feature_pipeline\n",
        "\n",
        "# load data with fallback path\n",
        "DATA_PATH = \"data/nba_shots_clean.csv\"\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    alt_path = os.path.join(\"..\", \"data\", \"nba_shots_clean.csv\")\n",
        "    if os.path.exists(alt_path):\n",
        "        DATA_PATH = alt_path\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            \"nba_shots_clean.csv not found. Run the cleaning notebook to generate it.\"\n",
        "        )\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Loaded dataset shape:\", df.shape)\n",
        "dtype_counts = df.dtypes.astype(str).value_counts()\n",
        "print(\"Datatype coverage (cleaned data):\\n\", dtype_counts)\n",
        "\n",
        "available_feature_columns = [c for c in df.columns if c != \"SHOT_MADE_FLAG\"]\n",
        "print(f\"Available feature columns (excluding target): {len(available_feature_columns)}\")\n",
        "print(\"Sample preserved columns:\", available_feature_columns[:10])\n",
        "\n",
        "X = df[[\"LOC_X\", \"LOC_Y\", \"SHOT_DISTANCE\", \"YEAR\", \"SHOT_TYPE\", \"ACTION_TYPE\"]]\n",
        "y = df[\"SHOT_MADE_FLAG\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train.head(), y_train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build preprocessing\n",
        "preprocessor, feature_list = build_feature_pipeline(df)\n",
        "\n",
        "# Baseline logistic regression\n",
        "log_reg_model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"clf\", LogisticRegression(max_iter=500)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = log_reg_model.predict(X_test)\n",
        "y_prob_lr = log_reg_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Accuracy (LR):\", round(accuracy_score(y_test, y_pred_lr), 3))\n",
        "print(\"ROC-AUC (LR):\", round(roc_auc_score(y_test, y_prob_lr), 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoost model (optional; requires libomp on macOS)\n",
        "xgb_available = True\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except Exception as e:  # ImportError or missing libomp\n",
        "    xgb_available = False\n",
        "    print(\"XGBoost not available. Install with `pip install xgboost` and on macOS run `brew install libomp`.\")\n",
        "    print(\"Skipping XGBoost training. Error:\", e)\n",
        "\n",
        "if xgb_available:\n",
        "    try:\n",
        "        model_xgb = Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocess\", preprocessor),\n",
        "                (\n",
        "                    \"clf\",\n",
        "                    XGBClassifier(\n",
        "                        n_estimators=300,\n",
        "                        learning_rate=0.05,\n",
        "                        max_depth=6,\n",
        "                        subsample=0.8,\n",
        "                        colsample_bytree=0.8,\n",
        "                        eval_metric=\"logloss\",\n",
        "                        n_jobs=-1,\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        model_xgb.fit(X_train, y_train)\n",
        "\n",
        "        y_prob_xgb = model_xgb.predict_proba(X_test)[:, 1]\n",
        "        print(\"ROC-AUC (XGB):\", round(roc_auc_score(y_test, y_prob_xgb), 3))\n",
        "    except Exception as e:\n",
        "        xgb_available = False\n",
        "        print(\"XGBoost failed to train; skipping. Error:\", e)\n",
        "        print(\"On macOS, run: brew install libomp\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# only save if XGBoost trained successfully\n",
        "if \"model_xgb\" in locals() and xgb_available:\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    model_path = \"models/shot_model_xgb.pkl\"\n",
        "    joblib.dump(model_xgb, model_path)\n",
        "    print(\"Saved XGB model to\", model_path)\n",
        "else:\n",
        "    print(\"XGBoost model not available; skipping save.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
